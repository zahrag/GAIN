from __future__ import print_function

import json
import numpy as np

from networkx.readwrite import json_graph
import exps_logs

''' 
    Authors: Zahra Gharaee (zahra.gharaee@liu.se)
    Example: python osm_eval.py 
    
    This script contains codes to evaluate the performance of GAIN architecture.
    It evaluates representation vectors generated by GAIN trained for road types classification problem.
    Running this script shows the results of random-baseline, raw-features only, and the representation vectors trained 
    by GAIN when test input composed of unseen nodes (transductive) and unseen graphs (inductive) are used in 
    supervised and unsupervised settings.
    
    In unsupervised learning, it calculates micro-averaged F1-Score of the classifier 
    trained and averaged for 1000 trials on the representation vectors of unseen test input applying the 
    best performing model. Best performing model has the maximum micro-averaged F1-Scores of the classifier trained 
    (for 1000 trials) on the representation vectors of the validation input generated by all models 
    of the exhaustive grid search. 1000 trials of training the classifier on the representation vectors 
    is to achieve stability and robustness of the results by getting the standard deviation close to zero.
    
    In supervised learning, micro-averaged F1-Score of the class labels predicted by our best model when applying test 
    input is computed. Best performing model has the maximum micro-averaged F1-Scores of the class labels predicted by 
    all models of the exhaustive grid search when applying validation input.
    
    '''


def get_data_labels(dataset_dir, train_prefix, setting=None):

    G = json_graph.node_link_graph(json.load(open(dataset_dir + "/" + train_prefix + "G.json")))
    labels = json.load(open(dataset_dir + "/" + train_prefix + "class_map.json"))

    train_ids = [n for n in G.nodes() if not G.nodes[n]['val'] and not G.nodes[n]['test']]
    test_ids = [n for n in G.nodes() if G.nodes[n][setting]]
    train_labels = [labels[str(i)] for i in train_ids]
    test_labels = [labels[str(i)] for i in test_ids]

    return train_labels, test_labels, train_ids, test_ids


def get_data_feat(dataset_dir, train_prefix, train_ids, test_ids):
    # print("Using features..")
    feats = np.load(dataset_dir + "/" + train_prefix + "feats.npy")
    # # Logistic gets thrown off by big counts, so log transform num comments and score
    feats[:, 0] = np.log(feats[:, 0] + 1.0)
    feats[:, 1] = np.log(feats[:, 1] - min(np.min(feats[:, 1]), -1))

    feat_id_map = json.load(open(dataset_dir + "/" + train_prefix + "id_map.json"))
    # feat_id_map = {int(id): val for id, val in feat_id_map.iteritems()}
    feat_id_map = {int(id): val for id, val in feat_id_map.items()}

    train_feats = feats[[feat_id_map[id] for id in train_ids]]
    test_feats = feats[[feat_id_map[id] for id in test_ids]]

    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    scaler.fit(train_feats)
    train_feats = scaler.transform(train_feats)
    test_feats = scaler.transform(test_feats)

    return train_feats, test_feats


def get_data_embed(data_dir, train_ids, test_ids):
    embeds = np.load(data_dir + "/val.npy")
    id_map = {}
    with open(data_dir + "/val.txt") as fp:
        for i, line in enumerate(fp):
            id_map[int(line.strip())] = i
    train_embeds = embeds[[id_map[id] for id in train_ids]]
    test_embeds = embeds[[id_map[id] for id in test_ids]]

    return train_embeds, test_embeds


def run_regression(train_data, train_labels, test_data, test_labels, setting=None, rand_baseline=None):
    np.random.seed(1)
    from sklearn.linear_model import SGDClassifier
    from sklearn.dummy import DummyClassifier
    from sklearn.metrics import f1_score
    from sklearn.metrics import recall_score
    from sklearn.metrics import accuracy_score
    from sklearn.metrics import precision_score

    tr_res = []
    ts_res = []
    if rand_baseline:
        dummy = DummyClassifier(strategy='uniform')  # 'stratified' 'uniform', "most_frequent"
        dummy.fit(train_data, train_labels)
        tr_res.append(f1_score(train_labels, dummy.predict(train_data), average="micro"))
        ts_res.append(f1_score(test_labels, dummy.predict(test_data), average="micro"))

    else:
        log = SGDClassifier(loss="log", max_iter=1000, tol=1e-3, n_jobs=55)
        log.fit(train_data, train_labels)

        # Train
        tr_res.append(f1_score(train_labels, log.predict(train_data), average="micro"))
        tr_res.append(accuracy_score(train_labels, log.predict(train_data)))
        tr_res.append(precision_score(train_labels, log.predict(train_data), average="micro"))
        tr_res.append(recall_score(train_labels, log.predict(train_data), average="micro"))

        # Test
        ts_res.append(f1_score(test_labels, log.predict(test_data), average="micro"))
        ts_res.append(accuracy_score(test_labels, log.predict(test_data)))
        ts_res.append(precision_score(test_labels, log.predict(test_data), average="micro"))
        ts_res.append(recall_score(test_labels, log.predict(test_data), average="micro"))

    return tr_res, ts_res


def calculate_results(tr_res, ts_res, setting=None):
    prefixes = ['train', setting]
    results = [tr_res, ts_res]
    dicts = [{}, {}]
    cols = ['f1']  # , 'accuracy', 'precision', 'recall']
    for prefix, result, dict in zip(prefixes, results, dicts):
        for i, col in enumerate(cols):
            dict[prefix + '_' + col + '_avg'] = np.mean(result[:, i])
            dict[prefix + '_' + col + '_std'] = np.std(result[:, i])
    return dicts


if __name__ == '__main__':

    # log_dir = '../logs/'
    # data_dir_base = '../graph_data/'

    # If you want to see the results of a pre-trained GAIN model
    log_dir = '../logs_GainRepo/'
    data_dir_base = '../graph_data_GainRepo/'

    # Initial Settings
    settings = ['transductive', 'inductive']

    prefixes = ['linkoping-osm-', 'sweden-osm-']

    supervision = ['unsupervised', 'supervised']

    random_baseline = True
    raw_feats = True
    embeds = True
    # number of trials to run regression classifier
    max_num_itr = 1000

    exp_ind = 0
    for ind, set in enumerate(settings):

        data_dir = data_dir_base + 'osm_' + set
        train_prefix = prefixes[ind]
        # --------- Train/Validation labels/ids
        print("\n**************** Loading {} data ..".format(set))
        train_labels, val_labels, train_ids, val_ids = get_data_labels(data_dir, train_prefix, setting='val')
        # --------- Test labels/ids
        train_labels, test_labels, train_ids, test_ids = get_data_labels(data_dir, train_prefix, setting='test')

        # --------- Train/test raw feature attributes
        train_feats, test_feats = get_data_feat(data_dir, train_prefix, train_ids, test_ids)

        # --------- Running random baseline
        if random_baseline:
            tr_res, test_res = run_regression(train_feats, train_labels, test_feats, test_labels, setting='test',
                                              rand_baseline=True)
            print('Results of learning Random baseline to classify road networks:', test_res[0])

        # --------- Running raw features/attributes only
        if raw_feats:
            tr_res, test_res = run_regression(train_feats, train_labels, test_feats, test_labels, setting='test',
                                              rand_baseline=False)
            print('Result of learning Raw features/attributes to classify road networks:', test_res[0])
            print('\n')

        if embeds:

            for ind_, sup in enumerate(supervision):
                result_dir = log_dir + 'osm_' + set + '/' + sup + '_gain_model'
                exp_ind += 1

                # --------- logs
                logs = exps_logs.get_logs(result_dir)

                if sup is 'unsupervised':

                    # Using learned embeddings of the dataset
                    train_embeds, val_embeds = get_data_embed(result_dir, train_ids, val_ids)
                    _, test_embeds = get_data_embed(result_dir, train_ids, test_ids)

                    all_tr_res = []
                    all_ts_res = []
                    for i in range(max_num_itr):
                        tr_res, ts_res = run_regression(train_embeds, train_labels, test_embeds, test_labels,
                                                        setting='test',
                                                        rand_baseline=False)

                        all_tr_res.append(tr_res)
                        all_ts_res.append(ts_res)

                    _, test_results = calculate_results(np.asarray(all_tr_res), np.asarray(all_ts_res), setting='test')

                    print('Result of {} learning representation by GAIN to classify road networks:'.format(sup),
                          test_results['test_f1_avg'])

                else:  # supervised

                   val_results, test_results = exps_logs.get_sup_results(result_dir)

                   print('Result of {} learning representation by GAIN to classify road networks:'.format(sup),
                         test_results['f1_micro='])
                   print('\n')



